from pyspark.sql import functions as F
from pyspark.sql.window import Window

# Create a window with partition by Partition and order by Order
w = Window.partitionBy("Partition").orderBy("Order")

# Use the lag and lead functions to get the previous and next values of Flags
df = df.withColumn("prev", F.lag("Flags").over(w))
df = df.withColumn("next", F.lead("Flags").over(w))

# Use a case when expression to check the logic for each row and add a new column Keep
df = df.withColumn("Keep", F.expr("""
case 
  when Flags = 0 and (next = 0 or next is null) then true
  when Flags = 1 and (prev = 1 or prev is null) and (next = 1 or next is null) then true
  else false
end
"""))

# Show the result
df.show()
